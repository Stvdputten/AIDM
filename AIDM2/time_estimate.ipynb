{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Advances in Data Mining**\n",
    "\n",
    "Stephan van der Putten | (s1528459) | stvdputtenjur@gmail.com  \n",
    "Theo Baart | s2370328 | s2370328@student.leidenuniv.nl\n",
    "\n",
    "### **Assignment 2**\n",
    "This assignment is concerned with finding the set of similar users in the provided datasource. To be more explicit, in finding all pairs of users who have a Jaccard similarity of more than 0.5. Additionally, this assignment considers comparing the \"naïve implementation\" with the \"LSH implementation\". The \"naïve implementation\" can be found in the file `time_estimate.ipynb` and the \"LSH implementation\" in the file `lsh.ipynb`.\n",
    "\n",
    "Note all implementations are based on the assignment guidelines and helper files given as well as the documentation of the used functions. \n",
    "\n",
    "#### **Naïve Implementation**\n",
    "This notebook implements a naïve algorithm to find all pairs of users with a Jaccard similarity of more than 0.5. As noted in the assignment instructions the duration of the algorithm might be far to great to ever achieve execution in a reasonable time. As such, this file includes tests in order to extrapolate and estimate what the total run time of a full execution would be. This estimate is also the only output delivered by this notebook.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet handles all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Functions**\n",
    "This section contains multiple helper functions whichplay a role in determining what the estimated total runtime is for the naïve algorithm for user pair similarity.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_sample` function is a helper function which returns a subset of the given array. This function is based on the following: \n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `data` - the array for which we want a subset\n",
    "  * `sample_rate` - the rate with which we want to down-sample (between 0.0 and 1.0). A `sample_rate` of 0.25 means that the returned subset is 25% of the original.\n",
    "  \n",
    "Additionally, it returns the following value:\n",
    "  * `sample` - the down-sampled subset of the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(data,sample_rate):\n",
    "    mask = np.random.choice([False, True], len(data), p=[1-sample_rate, sample_rate])\n",
    "    sample = data[mask]\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_columns` function takes an array of users and movies and returns a dictionary of columns. Each column contains the movies watched by a given users.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `array` - the array from which we want to retrieve the columns\n",
    "  \n",
    "Additionally, it returns the following value:\n",
    "  * `columns` - a dictionary of columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(array):  \n",
    "#     %time df = pd.DataFrame({'User':array[:,0],'Movie':array[:,1]})\n",
    "#     %time ct = pd.crosstab(df.Movie, df.User)\n",
    "#     %time matrix = ct.to_numpy()\n",
    "    users = np.unique(array[:,0])\n",
    "    columns = {}\n",
    "    for user in users:\n",
    "        rows = array[np.where(array[:,0]==user)]\n",
    "        column = rows[:,1]\n",
    "        columns[user] = column\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_jaccard` function receives two columns and returns the jaccard similarity of the two columns.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `c1` - the first column\n",
    "  * `c2` - the second column\n",
    "  \n",
    "Additionally, it returns the following value:\n",
    "  * `jaccard` - the Jaccard similarity of `c1` and `c2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard(c1,c2):\n",
    "    s1 = set(c1)\n",
    "    s2 = set(c2)\n",
    "    union = s1.union(s2)\n",
    "    intersection = s1.intersection(s2)\n",
    "    jaccard = len(intersection) / len(union)\n",
    "    return jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_pairs` function iterates over the columns and returns all columns with a Jaccard similarity above 0.5.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `columns` - a dictionary of columns which may potentially be matched\n",
    "  \n",
    "Additionally, it returns the following value:\n",
    "  * `pairs` - a list of user pairs with a Jaccard similarity above 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(columns):\n",
    "    pairs = []\n",
    "    users = list(columns.keys())\n",
    "    u = len(users)\n",
    "    for i in range(u):\n",
    "        user =users[i]\n",
    "        column = columns[user]\n",
    "        for j in range(i+1,u):\n",
    "            other_user = users[j]\n",
    "            other_column = columns[other_user]\n",
    "            if get_jaccard(column,other_column) > 0.5:\n",
    "                pairs.append([user,other_user])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scale_interim` estimates what the runtime for a full data set would be given a sample rate and the runtime for this sample rate.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `interim` - the run time to be scaled\n",
    "  * `users_sample` - the number of users in the sample\n",
    "  * `users_full` - the number of users in the full data set\n",
    "  \n",
    "Additionally, it returns the following value:\n",
    "  * `runtime` - the estimated scaled runtime for the naïve algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_interim(interim, users_sample, users_full):\n",
    "    full_comparisons = (users_full * users_full) / 2\n",
    "    interim_comparisons = (users_sample * users_sample) / 2\n",
    "    scale_factor = full_comparisons / interim_comparisons\n",
    "    \n",
    "    runtime = scale_factor * interim\n",
    "    return runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Execution**\n",
    "This section is concerned with running multiple tests in order to determine what the estimated total runtime is for the naïve algorithm for user pair similarity.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `time_estimator` function is the main runner for determining the total runtime for the naïve algorithm.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `data` - the raw data from `user_movie.npy`\n",
    "  * `sample_rate` - the sample size to use for estimating the total runtime (between 0.0 and 1.0)\n",
    "  * `sample_count` - the number of samples to take\n",
    "  \n",
    "Additionally, it returns the following value:\n",
    "  * `runtime` - the final estimated runtime for the naïve algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_estimator(data, sample_rate, sample_count):\n",
    "    durations = []\n",
    "    users_samples = []\n",
    "    for i in range(sample_count):   \n",
    "        start_run = timeit.default_timer()\n",
    "        subset = get_sample(data, sample_rate)\n",
    "        columns = get_columns(subset)\n",
    "        pairs = get_pairs(columns)\n",
    "        end_run = timeit.default_timer()\n",
    "        users_samples.append(len(columns.keys()))\n",
    "        durations.append((end_run - start_run))\n",
    "    interim = np.mean(durations)\n",
    "    users_full = len(np.unique(data[:,0]))\n",
    "    users_sample = np.mean(users_samples)\n",
    "    final = scale_interim(interim,users_sample,users_full)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Program Execution**\n",
    "This section is concerned with parsing the input arguments and determining the execution flow of the program.\n",
    "___\n",
    "The `main` function handles the start of execution from the command line.\n",
    "\n",
    "The following command line arguments are expected:\n",
    "  * `path` - the location of the `user_movies.npy` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path):    \n",
    "    # convert path to matrix\n",
    "    data = np.load(path)\n",
    "    \n",
    "    # execute time estimator\n",
    "    sample_rate = 0.0001\n",
    "    sample_count = 4\n",
    "    estimate = time_estimator(data,sample_rate,sample_count)\n",
    "    print(estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet passes the start of the program and the command line arguments to the `main` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path = sys.argv[1]\n",
    "    main(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
