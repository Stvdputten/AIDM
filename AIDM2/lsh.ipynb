{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Advances in Data Mining**\n",
    "\n",
    "Stephan van der Putten | (s1528459) | stvdputtenjur@gmail.com  \n",
    "Theo Baart | s2370328 | s2370328@student.leidenuniv.nl\n",
    "\n",
    "### **Assignment 2**\n",
    "This assignment is concerned with finding the set of similar users in the provided datasource. To be more explicit, in finding all pairs of users who have a Jaccard similarity of more than 0.5. Additionally, this assignment considers comparing the \"naïve implementation\" with the \"LSH implementation\". The \"naïve implementation\" can be found in the file `time_estimate.ipynb` and the \"LSH implementation\" in the file `lsh.ipynb`.\n",
    "\n",
    "Note all implementations are based on the assignment guidelines and helper files given as well as the documentation of the used functions. Additionally, the following sources have been referenced and used as inspiration:\n",
    "  1. CMSC643: Machine Learning and Data Mining: <http://www.hcbravo.org/dscert-mldm/projects/project_1/>\n",
    "  2. Shared_Minhash_and_LSH_from_binned_date: <https://colab.research.google.com/drive/1HetBrWFRYqwUxn0v7wIwS7COBaNmusfD#scrollTo=hzPw8EMoW4i4&forceEdit=true&sandboxMode=true>\n",
    "\n",
    "\n",
    "#### **LSH Implementation**\n",
    "This notebook implements LSH in order to find all pairs of users with a Jaccard similarity of more than 0.5. As noted in the assignment instructions the data file is loaded from `user_movie.npy` and the list of user pairs are printed in the file `ans.txt`. Additionally, this implementation supports the setting of a random seed to determine the permutations to be used in LSH. The algorithm will continually save its output so as to aid in the evaluation criteria which only looks at the first 15 minutes of the LSH execution.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Functions**\n",
    "This section contains functions which aid and simplify the code for our LSH implementation\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet handles all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import defaultdict\n",
    "import scipy.optimize as opt\n",
    "import math\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `compute_num_bands` function computes the optimal number of bands to use given a threshold and signature size. This is a slightly modified version of the `choose_nbands` function given in [1].\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `t` - the desired threshold value\n",
    "  * `s` - the size of the signature\n",
    "  \n",
    "Additionally, it returns the following values:\n",
    "  * `b` - the suggested number of bands to use\n",
    "  * `final_t` - the computed threshold for this number of bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_num_bands(t, s):\n",
    "    def error_fun(x):\n",
    "        cur_t = (1/x[0])**(x[0]/s)\n",
    "        return (t-cur_t)**2\n",
    "\n",
    "    opt_res = opt.minimize(error_fun, x0=(10), method='Nelder-Mead')\n",
    "    b = int(math.ceil(opt_res['x'][0]))\n",
    "    r = round(s / b)\n",
    "    final_t = (1/b)**(1/r)\n",
    "    return b, final_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_signature_hash_function` function generates a random hash function which returns a large numeric value to be used for hashing signatures into buckets. This is a slightly modified version of the `make_random_hash_fn` function given in [1].\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `p` - largest value which can be randomly selected [default: 2^31 - 1]\n",
    "  * `k` - the number of buckets to use [default: 12884901885]\n",
    "  \n",
    "Additionally, it returns the following value:\n",
    "  * `lambda` - a lambda function representing the random hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_signature_hash_function(p=2**31-1, k=12884901885):#4294967295):\n",
    "    a = np.random.randint(1,p-1)\n",
    "    b = np.random.randint(0, p-1)\n",
    "    return lambda x: ((a * x + b) % p) % k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `write_pair_to_file` function writes the given pair of users to the specified file.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `pair` - the pair of users to write to the file\n",
    "  * `path` - the filepath of the file to write to  [`ans.txt`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_pair_to_file(pair,path='ans.txt'):\n",
    "    file = open(path, \"a+\")\n",
    "    line = str(pair[0]) + ', ' + str(pair[1]) + '\\r\\n'\n",
    "    file.write(line)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LSH Class**\n",
    "\n",
    "This section contains the class and its functions which execute the various steps of the LSH algorithm. Due to the limitations of `.ipynb` files the various functions will be described first and then the implementation will be shown.\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "The `__init__` function initializes the class and sets the random seed to a specific value.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `dataset` - the raw user-movie data [default: None]\n",
    "  * `sparse_matrix` - the sparse matrix to use [default: None]\n",
    "  * `signature_length` - the number of signatures/permutations to use [default: 50]\n",
    "  * `permutations` - the array of permutations to use [default: None]\n",
    "  * `signature_matrix` - the signature matrix to use [default: None]\n",
    "  * `buckets` - the LSH buckets to use [default: None]\n",
    "  * `random_seed` - the seed to use for generating random numbrs [default: 10102020]\n",
    "___\n",
    "The `load` function loads data and stores it in `dataset`.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `path` - the location of the data to load\n",
    "___\n",
    "The `create_sparse_matrix` function transforms the dataset into a sparse matrix such that a 1 signifies that a user [column] has watched that specific movie [row]\n",
    "___\n",
    "The `generate_permutations` function generates an array of `signature_lenght` random permutations of the rows in the `sparse_matrix`.\n",
    "___\n",
    "The `generate_signature_matrix` function generates the `signature_matrix` by minhashing the permutations on the `sparse_matrix`. This function is a modified implementation of the `minhash_signature` function in [2].\n",
    "___\n",
    "the `split_to_buckets` function takes the signature matrix, applies banding and then places the users [columns] into buckets. This function is based on the implementations of `do_lsh` in [1] and `lsh_r_bucket_to_id` in [2].\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `b` - the number of bands to use\n",
    "  * `r` - the number of rows to use\n",
    "  ___\n",
    "the `get_pairs_from_buckets` function takes LSH buckets and extracts the user pairs with a similarity > 0.5. Additionally, these pairs are written to file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LSH():\n",
    "    \n",
    "    def __init__(self, dataset=None, sparse_matrix=None, \n",
    "                 signature_length=50, permutations=None, signature_matrix=None, buckets=None, random_seed=10102020):\n",
    "        self.dataset = dataset\n",
    "        self.signature_length = signature_length\n",
    "        self.sparse_matrix = sparse_matrix\n",
    "        self.permutations = hash_func\n",
    "        self.signature_matrix = signature_matrix\n",
    "        self.buckets = buckets\n",
    "        np.random.seed(seed=random_seed)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.dataset = np.load(path)\n",
    "     \n",
    "    def create_sparse_matrix(self):\n",
    "        c = dataset[:,0]\n",
    "        r = dataset[:,1]\n",
    "        d = np.ones(len(c))\n",
    "        max_c = len(np.unique(c))\n",
    "        max_r = len(np.unique(r))\n",
    "        self.sparse_matrix = csr_matrix((d,(r,c)), shape=(max_r, max_c))\n",
    "        \n",
    "    def generate_permutations(self):\n",
    "        self.permutations = np.array([np.random.permutation(self.sparse_matrix.shape[0]) for i in range(signature_length)])\n",
    "        \n",
    "    def generate_signature_matrix(self):\n",
    "        sigm = np.full((self.signature_length, self.sparse_matrix.shape[1]), np.inf)\n",
    "        number_of_rows = self.sparse_matrix.shape[0]\n",
    "        t1 = time.time() \n",
    "        for row in range(number_of_rows):\n",
    "            if row % 5000==0:\n",
    "                print(str(round(100*row/number_of_rows,2))+' percent complete in '+str(round(time.time()-t1,2))+ ' seconds')\n",
    "            ones = find(self.sparse_matrix[row, :])[1]\n",
    "            perm = self.permutations[:,row]\n",
    "            B = sigm.copy()\n",
    "            B[:,ones] = 1\n",
    "            B[:,ones] = np.multiply(B[:,ones], perm.reshape((len(perm), 1)))\n",
    "            sigm = np.minimum(sigm, B)\n",
    "        self.signature_matrix = sigm\n",
    "    \n",
    "    def split_to_buckets(self,b,r):\n",
    "        user_ids = np.array(list(range(self.signature_matrix.shape[1])))\n",
    "        number_of_users = self.signature_matrix.shape[1]\n",
    "        buckets = defaultdict(list)\n",
    "        hf = generate_signature_hash_function()\n",
    "        t1 = time.time()    \n",
    "        for i in range(number_of_users):\n",
    "            if i % 10000==0:\n",
    "                print(str(round(100*i/number_of_users,2))+' percent complete in '+str(round(time.time()-t1,2))+ ' seconds')\n",
    "            row = self.signature_matrix[:,i] \n",
    "            for j in range(b):\n",
    "                r_signature = str(row[j*r:(j+1)*r])\n",
    "                r_hash = hash(r_signature)\n",
    "                r_hash = hf(r_hash)\n",
    "                buckets[r_hash].append(user_ids[i])\n",
    "        buckets_set = {k: set(v) for k,v in buckets.items()}\n",
    "        self.buckets = buckets_set\n",
    "    \n",
    "    def get_pairs_from_buckets(self):\n",
    "        all_pairs = set ()\n",
    "        full_buckets = {k: v for k, v in self.buckets.items() if len(v) >= 2}\n",
    "        number_of_buckets = len(full_buckets)\n",
    "        counter = 0\n",
    "        t1 = time.time()  \n",
    "        for v in full_buckets.values():\n",
    "            if counter % 10000==0:\n",
    "                print(str(round(100*counter/number_of_buckets,2))+' percent complete in '+str(round(time.time()-t1,2))+ ' seconds')\n",
    "            counter += 1\n",
    "            bucket_pairs = set(it.combinations(v,2))\n",
    "            for pair in bucket_pairs:\n",
    "                if pair not in all_pairs:\n",
    "                    write_pair_to_file(pair)\n",
    "            all_pairs.update(bucket_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Program Execution**\n",
    "This section is concerned with parsing the input arguments and determining the execution flow of the program.\n",
    "\n",
    "___\n",
    "The `main` function handles the command line arguments and is responsible for the main flow of the program.\n",
    "\n",
    "In order to do this the function uses the following parameter:\n",
    "  * `path` - the location fo the `user_movies.npy` file [default = 'datasets/user_movie.npy']\n",
    "  * `threshold` - the targeted threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(path = 'datasets/user_movie.npy', threshold = 0.5):\n",
    "    lsh = LSH()\n",
    "    lsh.load(path)\n",
    "    \n",
    "    lsh.create_sparse_matrix()\n",
    "    lsh.generate_permutations()\n",
    "    lsh.generate_signature_matrix()\n",
    "    # uncomment to skip some steps [REMOVE WHEN HANDING IN]\n",
    "#     sigm100 = np.load('datasets/sign_matrix_100.npy')\n",
    "#     sigm50 = np.load('datasets/sign_matrix.npy')\n",
    "\n",
    "    b, _t = compute_num_bands(threshold, lsh.signature_length)\n",
    "    r = round(lsh.signature_length / b)\n",
    "#     print(threshold, b, r, _t)\n",
    "    lsh.split_to_buckets(b,r)\n",
    "    lsh.get_pairs_from_buckets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet passes the start of the program and the command line arguments to the `main` function.\n",
    "\n",
    "The following command line argument is expected:\n",
    "  * `path` - the location of the `user_movies.npy` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path = sys.argv[1]\n",
    "    main(path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE FOLLOWINGS SNIPPETS ARE FOR TESTING/DEVELOPMENT AND SHOULD BE REMOVED BEFORE HANDING IT IN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO Elegance aka classes, comments/report/citation\n",
    "#TODO REMOVE/COMMENT ALL PRINT STATEMENTS! \n",
    "#TODO IMPROVE EFFICIENCY FOR LONGER SIGNATURES Time < 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 percent complete in 0.0 seconds\n",
      "3 3 0.5\n",
      "0.0 percent complete in 0.0 seconds\n",
      "0.0 percent complete in 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# SMALL SCALE EXAMPLE\n",
    "example = np.array([[1,0,0,1,1,0,0,1],[0,0,1,0,0,0,1,0],[0,0,1,0,0,0,1,0],[0,1,0,1,1,0,0,1],[1,0,1,0,1,0,1,0],[0,1,1,1,1,1,0,1]])\n",
    "hash_func = np.array([[5,4,3,1,2,0],[3,1,2,0,5,4],[1,2,0,5,4,3],[2,0,5,4,3,1],[0,5,4,3,1,2],[3,0,4,2,1,5],[0,4,2,1,5,3],[4,2,1,5,3,0],[2,1,5,3,0,4]])\n",
    "c = csr_matrix(example)\n",
    "lsh = LSH(dataset=example, sparse_matrix=c, \n",
    "                 signature_length=9, permutations=hash_func)\n",
    "lsh.generate_signature_matrix()\n",
    "b = 3\n",
    "r = round(9 / b)\n",
    "print(b,r,_t)\n",
    "lsh.split_to_buckets(b,r)\n",
    "lsh.get_pairs_from_buckets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
