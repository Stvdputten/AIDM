{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Advances in Data Mining**\n",
    "\n",
    "Stephan van der Putten | (s1528459) | stvdputtenjur@gmail.com  \n",
    "Theo Baart | s2370328 | s2370328@student.leidenuniv.nl\n",
    "\n",
    "### **Assignment 1**\n",
    "This assignment is concered with implementing formulas and models capable of predicting movie ratings for a set of users. Additionally, the accuracy of the various models are checked. \n",
    "\n",
    "Note all implementations are based on the assignment guidelines and helper files given as well as the documentation of the used functions.\n",
    "\n",
    "#### **Model Approach**\n",
    "This specific notebook handles the implementation of a Matrix factorization approach to the prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet handles all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Extraction and Preparation**\n",
    "\n",
    "The `convert_data` function is used to extract the data from the raw data file and store it in a format that is more convenient for us. \n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `path` - the (relative) location of the raw dataset (with filetype `.dat`)\n",
    "  * `cols` - which columns to load from the raw dataset\n",
    "  * `delim` - the delimitor used in the raw dataset\n",
    "  * `dt` - the datatype used for the data in the raw dataset\n",
    "    \n",
    "Additionally it returns the following value:\n",
    "  * `path` - the location at which the converted dataset is stored (with filetype `.npy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(path=\"datasets/ratings\",cols=(0,1,2),delim=\"::\",dt=\"int\"):\n",
    "    raw = np.genfromtxt(path+'.dat', usecols=cols, delimiter=delim, dtype=dt)\n",
    "    np.save(path+\".npy\",raw)\n",
    "    # check to see if file works\n",
    "    assert np.load(path+'.npy').all() == raw.all()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `prep_data` function is used to load the stored data and transform it into a usable and well defined dataframe. \n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `path` - the (relative) location of the converted dataset: if no file exists a new one is created\n",
    "    \n",
    "Additionally it returns the following value:\n",
    "  * `df_ratings` - a dataframe containing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(path='datasets/ratings'):\n",
    "    filepath = path+'.npy'\n",
    "    if not os.path.isfile(filepath):\n",
    "        filepath = convert_data()\n",
    "    ratings = np.load(filepath)\n",
    "    df_ratings = pd.DataFrame(ratings)\n",
    "    colnames = ['UserId', 'MovieId', 'Rating']\n",
    "    df_ratings.columns = colnames\n",
    "    return df_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet is responsible for running the extraction and preparation of the raw data. The data is stored in `df_ratings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = prep_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rating Model**\n",
    "\n",
    "The following functions are used to model and predict user ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_model` function computes a model which can be used for predicting a users rating for a requested movie. If no training data can be used estimates are generated using the naive `rating_user_item` approach. Additionally, all ratings are squeezed to be between 1 and 5.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `df` - the dataframe containing the dataset on which the model will be computed\n",
    "  * `eta` - the learning rate\n",
    "  * `lam` - the regularization factor\n",
    "  * `max_iter` - the maximum number of iterations allowed in attempting to find a local minimum\n",
    "  * `seed` - the random seed to use for generating the initial weights\n",
    "  * `alpha` - [for unrated combos] the weight for the average user rating\n",
    "  * `beta` -  [for unrated combos] the weight for the average user rating\n",
    "  * `gamma` - [for unrated combos] the offset/modifier for the generated prediction\n",
    "    \n",
    "Additionally it returns the following values:\n",
    "  * `model` - a vector containing the predicted rating for each movie\n",
    "  * `rmse` - the root-mean-square-error for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(df,eta=0.001,lam=0.01,max_iter=1000,seed=22070219,alpha=0.78212853,beta=0.87673970,gamma=-2.35619748):\n",
    "    # initialize parameters\n",
    "    matrix = np.nan_to_num(pd.crosstab(df.UserId,df.MovieId,values=df.Rating,aggfunc='mean').to_numpy())\n",
    "    u = df['UserId'].nunique()\n",
    "    i = df['MovieId'].nunique()\n",
    "    np.random.seed = seed\n",
    "    user = np.random.rand(u,1)\n",
    "    item = np.random.rand(1,i)\n",
    "    error = np.full((u, i), np.nan)\n",
    "    prev_rmse = np.inf\n",
    "    rmse = np.inf\n",
    "    curr_rmse = 0\n",
    "    n = 0\n",
    "    \n",
    "    # iterate over all records\n",
    "    while prev_rmse != curr_rmse:\n",
    "        it = np.nditer(matrix, flags=['multi_index'],op_flags=['readwrite'])\n",
    "        while not it.finished:\n",
    "            rating = it[0]\n",
    "            if rating is np.nan:\n",
    "                it.iternext() # skip if no known rating\n",
    "\n",
    "            a,b = it.multi_index\n",
    "            u_user = user[a][0]\n",
    "            i_item = item[0][b]\n",
    "\n",
    "            err = rating - (u_user * i_item)\n",
    "            u_user = u_user + eta * ((err * i_item) - (lam * u_user))\n",
    "            i_item = i_item + eta * ((err * u_user) - (lam * i_item))\n",
    "\n",
    "            user[a][0] = u_user\n",
    "            item[0][b] = i_item\n",
    "            error[a][b] = err\n",
    "            it.iternext()\n",
    "        prev_rmse = rmse\n",
    "        rmse = curr_rmse \n",
    "        curr_rmse = np.sqrt(np.nanmean(np.square(error)))\n",
    "        if n == max_iter:\n",
    "            break\n",
    "        n += 1\n",
    "\n",
    "    model = np.dot(user,item)\n",
    "    \n",
    "    # replace random weights of the non-rated user/movie combos with equally weighted average rating for that movie and that user\n",
    "    item_mean = np.nanmean(model,axis=0)\n",
    "    user_mean = np.nanmean(model,axis=1)\n",
    "    inds = np.where(np.isnan(np.where(matrix==0,np.nan,matrix)))\n",
    "    model[inds] = (alpha*np.take(user_mean,inds[0]) + beta*np.take(item_mean,inds[1]) + gamma)\n",
    "    \n",
    "    # ensure ratings are between 1 and 5\n",
    "    model[model < 1] = 1\n",
    "    model[model > 5] = 5\n",
    "    \n",
    "    return model, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_best_model` function retreives the model with the lowest rmse for various combinations of `eta` (learning rate) and `lam` (regularization factor).\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `df` - the dataframe containing the dataset on which the model will be computed\n",
    "\n",
    "  * `max_iter` - the maximum number of iterations allowed in attempting to find a local minimum\n",
    "  * `max_progression` - the number of different `eta` and `lam` values to be tested (e.g. lenght of the geometric progression)\n",
    "  * `progression_ratio` - the ratio to be used when generating the geometric progression\n",
    "  \n",
    "Additionally it returns the following values:\n",
    "  * `model` - a vector containing the best predicted ratings for each user/model.\n",
    "  * `rmse` - the root-mean-square-error for the best model\n",
    "  * `eta` - the learning rate of the best model\n",
    "  * `lam` - the regularization factor of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(df,max_progression = 4,progression_ratio=3):\n",
    "    max_iter=1000\n",
    "    eta_progression = [0.001 * progression_ratio**i for i in range(max_progression)]\n",
    "    lam_progression = [0.01 * progression_ratio**i for i in range(max_progression)]\n",
    "    best_model = []\n",
    "    best_rmse = np.inf\n",
    "    best_eta = 0\n",
    "    best_lam = 0\n",
    "    for i in range(max_progression):\n",
    "        model, rmse = generate_model(df,eta=eta_progression[i],lam=lam_progression[i],max_iter=max_iter)\n",
    "        if rmse < best_rmse:\n",
    "            best_model = model\n",
    "            best_rmse = rmse\n",
    "            best_eta = eta_progression[i]\n",
    "            best_lam = lam_progression[i]\n",
    "        if i != (max_progression - 1):\n",
    "            model, rmse = generate_model(df,eta=eta_progression[i+1],lam=lam_progression[i],max_iter=max_iter)\n",
    "            if rmse < best_rmse:\n",
    "                best_model = model\n",
    "                best_rmse = rmse\n",
    "                best_eta = eta_progression[i+1]\n",
    "                best_lam = lam_progression[i]\n",
    "            model, rmse = generate_model(df,eta=eta_progression[i],lam=lam_progression[i+1],max_iter=max_iter)\n",
    "            if rmse < best_rmse:\n",
    "                best_model = model\n",
    "                best_rmse = rmse\n",
    "                best_eta = eta_progression[i]\n",
    "                best_lam = lam_progression[i+1]\n",
    "    return best_model, best_rmse, best_eta, best_lam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet retrieves the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has rmse of 1.4545704263120838 and eta of 0.001 and lam of 0.01\n"
     ]
    }
   ],
   "source": [
    "X = df_ratings #.iloc[:200]\n",
    "model, rmse, eta, lam = get_best_model(X)#\\\n",
    "#model, rmse, eta, lam = get_best_model(df_ratings)\n",
    "np.savez('datasets/model-rmse-eta-lam', model, rmse, eta, lam)\n",
    "print('The best model has rmse of '+str(rmse)+' and eta of '+str(eta)+' and lam of '+str(lam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rating_model` function predicts the user's ratings for a certain movie by implenting Matrix factorization with Gradient Descent. \n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `model` - the model to be used to retrieve the ratings\n",
    "  * `df` - the dataframe containing the dataset\n",
    "  * `user` - the user for which a rating is requested\n",
    "  * `item` - the movie for which a rating is requested \n",
    "    \n",
    "Additionally it returns the following value:\n",
    "  * `rating` - the predicted rating for the requested movie by the requested user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_model(model,df,user,item):\n",
    "    users = df['UserId'].unique()\n",
    "    u = np.where(users == user)[0][0]\n",
    "    items = df['MovieId'].unique()\n",
    "    i = np.where(items == item)[0][0]\n",
    "    rating = model[u][i] \n",
    "    return rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet executes a test run of the rating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = rating_model(model,X,1,1193)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cross-validation**\n",
    "\n",
    "The accuracy of the model is computed through 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run_validation` function executes `n`-fold validation for a given function and initial data set. The initial data is split into `n` test and training folds for which the error is computed. The average error gives an indication of the accuracy of the rating function. \n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `model` - the model to be used to retrieve the ratings\n",
    "  * `df` - the dataframe containing the original dataset\n",
    "  * `n` - the number of folds to be generated\n",
    "  * `seed` - the random seed to be used\n",
    "    \n",
    "Additionally it returns the following value:\n",
    "  * `train_error` - the average error for this function on the training set\n",
    "  * `test_error` - the average error for this function on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation(m,df,n=5,seed=17092019):\n",
    "    err_train = np.zeros(n)\n",
    "    err_test = np.zeros(n)\n",
    "    print(df)\n",
    "    kf = KFold(n_splits=n, shuffle=True,random_state=seed)\n",
    "\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        df_train, df_test = df.iloc[train_index].copy(), df.iloc[test_index].copy()\n",
    "        \n",
    "        # run function on training set\n",
    "        df_train.loc[:,'RatingTrained'] = [rating_model(model=m,df=df_train,user=u,item=i) for u, i in zip(df_train['UserId'],df_train['MovieId'])]\n",
    "#         print(i,'trained')\n",
    "        # compute error on train set\n",
    "        df_train.loc[:,'DiffSquared'] = [(t - r)**2 for t, r in zip(df_train['RatingTrained'],df_train['Rating'])]\n",
    "        err_train[i] = np.sqrt(np.mean(df_train['DiffSquared']))\n",
    "#         print(i,'train error')\n",
    "        # compute error on test set\n",
    "        df_test.loc[:,'DiffSquared'] = [(rating_model(model=m,df=df_test,user=u,item=i) - r)**2 for u, i, r in zip(df_test['UserId'],df_test['MovieId'],df_test['Rating'])]\n",
    "        err_test[i] = np.sqrt(np.mean(df_test['DiffSquared']))  \n",
    "#         print(i,'test trained and error')\n",
    "        i = i + 1\n",
    "    # compute total error\n",
    "    train_error = np.mean(err_train)\n",
    "    test_error = np.mean(err_test)\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet computes the mean train and test errors for the `rating_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     UserId  MovieId  Rating\n",
      "0         1     1193       5\n",
      "1         1      661       3\n",
      "2         1      914       3\n",
      "3         1     3408       4\n",
      "4         1     2355       5\n",
      "..      ...      ...     ...\n",
      "195       3     1291       4\n",
      "196       3     1259       5\n",
      "197       3      653       4\n",
      "198       3     2167       5\n",
      "199       3     1580       3\n",
      "\n",
      "[200 rows x 3 columns]\n",
      "Mean training error: 2.5078173511031943\n",
      "Mean test error: 2.398519760515495\n"
     ]
    }
   ],
   "source": [
    "train, test = run_validation(model,X)\n",
    "#train, test = run_validation(model,df_ratings)\n",
    "np.savez('datasets/train_test_model', train, test)\n",
    "print(\"Mean training error: \" + str(train))\n",
    "print(\"Mean test error: \" + str(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cross-validation Results**\n",
    "\n",
    "As can be seen by running the `run_validation` function for the various rating function the performance for each function vastly differs. This is obvious as each function takes a more detailed look (i.e. considers more factors) into what could influence the rating. TODO TODO TODO TODO\n",
    "\n",
    "Below is an ordered list ranking the different functions from most accurate (lowest mean test error) to least accurate:\n",
    "  1. `rating_model` - test error of XX and training error of YY\n",
    "  2. `rating_user_item` - test error of XX and training error of YY\n",
    "  3. `rating_TODO` - test error of XX and training error of YY \n",
    "  4. `rating_TODO` - test error of XX and training error of YY\n",
    "  5. `rating_global` - test error of XX and training error of YY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
