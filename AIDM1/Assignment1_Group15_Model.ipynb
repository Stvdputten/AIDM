{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Advances in Data Mining**\n",
    "\n",
    "Stephan van der Putten | (s1528459) | stvdputtenjur@gmail.com  \n",
    "Theo Baart | s2370328 | s2370328@student.leidenuniv.nl\n",
    "\n",
    "### **Assignment 1**\n",
    "This assignment is concered with implementing formulas and models capable of predicting movie ratings for a set of users. Additionally, the accuracy of the various models are checked. \n",
    "\n",
    "Note all implementations are based on the assignment guidelines and helper files given as well as the documentation of the used functions.\n",
    "\n",
    "#### **Model Approach**\n",
    "This specific notebook handles the implementation of a Matrix factorization approach to the prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet handles all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Extraction and Preparation**\n",
    "\n",
    "The `convert_data` function is used to extract the data from the raw data file and store it in a format that is more convenient for us. \n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `path` - the (relative) location of the raw dataset (with filetype `.dat`)\n",
    "  * `cols` - which columns to load from the raw dataset\n",
    "  * `delim` - the delimitor used in the raw dataset\n",
    "  * `dt` - the datatype used for the data in the raw dataset\n",
    "    \n",
    "Additionally it returns the following value:\n",
    "  * `path` - the location at which the converted dataset is stored (with filetype `.npy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(path=\"datasets/ratings\",cols=(0,1,2),delim=\"::\",dt=\"int\"):\n",
    "    raw = np.genfromtxt(path+'.dat', usecols=cols, delimiter=delim, dtype=dt)\n",
    "    np.save(path+\".npy\",raw)\n",
    "    # check to see if file works\n",
    "    assert np.load(path+'.npy').all() == raw.all()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `prep_data` function is used to load the stored data and transform it into a usable and well defined dataframe. \n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `path` - the (relative) location of the converted dataset: if no file exists a new one is created\n",
    "    \n",
    "Additionally it returns the following value:\n",
    "  * `df_ratings` - a dataframe containing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(path='datasets/ratings'):\n",
    "    filepath = path+'.npy'\n",
    "    if not os.path.isfile(filepath):\n",
    "        filepath = convert_data()\n",
    "    ratings = np.load(filepath)\n",
    "    df_ratings = pd.DataFrame(ratings)\n",
    "    colnames = ['UserId', 'MovieId', 'Rating']\n",
    "    df_ratings.columns = colnames\n",
    "    return df_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet is responsible for running the extraction and preparation of the raw data. The data is stored in `df_ratings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = prep_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rating Model**\n",
    "\n",
    "The `rating_model` function predicts the user's ratings for a certain movie by implenting Matrix factorization with Gradient Descent.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `df` - the dataframe containing the dataset\n",
    "  * `user` - the user for which a rating is requested\n",
    "  * `item` - the movie for which a rating is requested \n",
    "    \n",
    "Additionally it returns the following value:\n",
    "  * `mean` - the predicted rating for the requested movie by the requested user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_model(df,user,item):\n",
    "    mean = 0.0 # TODO\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet executes a test run of the rating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = rating_model(df_ratings,1,1)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cross-validation**\n",
    "\n",
    "The accuracy of the model is computed through 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run_validation` function executes `n`-fold validation for a given function and initial data set. The initial data is split into `n` test and training folds for which the error is computed. The average error gives an indication of the accuracy of the rating function. \n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `df` - the dataframe containing the original dataset\n",
    "  * `function` a string representing name of the function to be tested\n",
    "  * `n` - the number of folds to be generated\n",
    "  * `seed` - the random seed to be used\n",
    "    \n",
    "Additionally it returns the following value:\n",
    "  * `train_error` - the average error for this function on the training set\n",
    "  * `test_error` - the average error for this function on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation(df,function,n=5,seed=17092019):\n",
    "    err_train = np.zeros(n)\n",
    "    err_test = np.zeros(n)\n",
    "    \n",
    "    kf = KFold(n_splits=n, shuffle=True,random_state=seed)\n",
    "#     print(kf)\n",
    "\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        df_train, df_test = df.iloc[train_index].copy(), df.iloc[test_index].copy()\n",
    "        \n",
    "        # run function on training set\n",
    "        df_train.loc[:,'RatingTrained'] = [function(df=df_train,user=u,item=i) for u, i in zip(df_train['UserId'],df_train['MovieId'])]\n",
    "#         print(i,'trained')\n",
    "        # compute error on train set\n",
    "        df_train.loc[:,'DiffSquared'] = [(t - r)**2 for t, r in zip(df_train['RatingTrained'],df_train['Rating'])]\n",
    "        err_train[i] = np.sqrt(np.mean(df_train['DiffSquared']))\n",
    "#         print(i,'train error')\n",
    "        # compute error on test set\n",
    "        df_test.loc[:,'DiffSquared'] = [(function(df=df_test,user=u,item=i) - r)**2 for u, i, r in zip(df_test['UserId'],df_test['MovieId'],df_test['Rating'])]\n",
    "        err_test[i] = np.sqrt(np.mean(df_test['DiffSquared']))  \n",
    "#         print(i,'test trained and error')\n",
    "        i = i + 1\n",
    "    # compute total error\n",
    "    train_error = np.mean(err_train)\n",
    "    test_error = np.mean(err_test)\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet computes the mean train and test errors for the `rating_model` function for various initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO ADD LOOP\n",
    "train, test = run_validation(df_ratings,rating_model)\n",
    "print(\"Mean training error: \" + str(train))\n",
    "print(\"Mean test error: \" + str(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above it is evident which configuration provides the best results for the model. TODO ADD EXPLANATION?\n",
    "\n",
    "Below is an ordered list ranking the different configurations from most accurate (lowest mean test error) to least accurate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cross-validation Results**\n",
    "\n",
    "As can be seen by running the `run_validation` function for the various rating function the performance for each function vastly differs. This is obvious as each function takes a more detailed look (i.e. considers more factors) into what could influence the rating. TODO TODO TODO TODO\n",
    "\n",
    "Below is an ordered list ranking the different functions from most accurate (lowest mean test error) to least accurate:\n",
    "  1. `rating_model` - test error of XX and training error of YY\n",
    "  2. `rating_user_item` - test error of XX and training error of YY\n",
    "  3. `rating_TODO` - test error of XX and training error of YY \n",
    "  4. `rating_TODO` - test error of XX and training error of YY\n",
    "  5. `rating_global` - test error of XX and training error of YY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
