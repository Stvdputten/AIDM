{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Advances in Data Mining**\n",
    "\n",
    "Stephan van der Putten | (s1528459) | stvdputtenjur@gmail.com  \n",
    "Theo Baart | s2370328 | s2370328@student.leidenuniv.nl\n",
    "\n",
    "### **Assignment 3**\n",
    "This assignment is concerned with performing an analysis of and execute PageRank on the wikipedia links given in the `wikilink_graph.2004-03-01.csv` file. In order to do this the assignment is split up into four subtasks with each subtask receiving its dedicated `.ipynb` file. See each specific file for details on what this notebook accomplishes.\n",
    "\n",
    "Note all implementations are based on the assignment guidelines and helper files given as well as the documentation of the used functions. \n",
    "\n",
    "#### **Exploratory Data Analysis**\n",
    "This notebook performs an exploratory analysis on the dataset. This includes some anlaysis on the nodes and edges as well as estimating system requirements for being able to execute the PageRank algorithm.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet handles all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_prepped_data` function is responsible for retrieving the data prepped by `prep.ipynb` and loading it for exploratory data analysis.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `filename` - the name of the file containing the prepped data [default = `prepped-data.npy`]\n",
    "  \n",
    "Additionally, it returns the following values:\n",
    "  * `data` - an array representing the prepped data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepped_data(filename = 'prepped_data.npy'):\n",
    "    data = np.load(filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet triggers data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_prepped_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dead Ends**\n",
    "This section is concerned with determining how many dead ends there are. A dead end refers to nodes which do not have any outgoing edges.\n",
    "___\n",
    "The `compute_dead_ends_set` function parses the nodes and computes a set of all nodes which are dead_ends. Analyzing the data it is evident that for a node to be in the dataset it must either have an outgoing edge or an incoming edge. By definition a dead end has no outgoing edges and therefore it must be in the list of incoming edges. Thus, the difference between the set of incoming edges and the set of outgoing edges is the set of dead ends.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `data` - the prepped data\n",
    "  \n",
    "Additionally, it returns the following values:\n",
    "  * `dead_ends` - a list of all the dead ends [in consecutive numbering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dead_ends_set(data):\n",
    "    with_outgoing_edges = set(data[:,0])\n",
    "    with_incoming_edges = set(data[:,1])\n",
    "#     print(with_outgoing_edges)\n",
    "#     print(with_incoming_edges)\n",
    "    dead_ends = with_incoming_edges - with_outgoing_edges\n",
    "#     print(dead_ends)\n",
    "    dead_ends = set(dead_ends)\n",
    "    return dead_ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `analyse_dead_ends` function analyzes the matrix and prints some data on the dead_ends in the graph.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `data` - the prepped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dead_ends(data):\n",
    "    dead_ends = compute_dead_ends_set(data)\n",
    "    count_dead_ends = len(dead_ends)\n",
    "    if count_dead_ends == 0:\n",
    "        print(\"There are no dead ends\")\n",
    "        return\n",
    "    # TODO convert consecutive numbering to original number\n",
    "    if count_dead_ends == 1:\n",
    "        print(\"There is 1 dead end.\")\n",
    "        print(\"The following node is classified as a dead end\")\n",
    "    else:\n",
    "        print(\"There are \"+str(len(dead_ends))+\" dead ends.\")\n",
    "        print(\"The following set of nodes are classified as dead ends.\")\n",
    "    print(dead_ends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet triggers the dead end analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 dead ends.\n",
      "The following set of nodes are classified as dead ends.\n",
      "{1, 3}\n"
     ]
    }
   ],
   "source": [
    "analyze_dead_ends(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO REMOVE ME I AM TEMPORARY!\n",
    "no_dead_ends = [[0,2],[1,2],[0,3],[2,1],[2,3],[3,1],[3,0]]\n",
    "one_dead_end = [[0,2],[0,3],[2,1],[2,3],[3,1],[3,0]]\n",
    "two_dead_ends = [[0,2],[0,3],[2,1],[2,3]]\n",
    "temp_data = two_dead_ends\n",
    "np.save('prepped_data',temp_data)\n",
    "data = load_prepped_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
