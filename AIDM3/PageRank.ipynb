{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Advances in Data Mining**\n",
    "\n",
    "Stephan van der Putten | (s1528459) | stvdputtenjur@gmail.com  \n",
    "Theo Baart | s2370328 | s2370328@student.leidenuniv.nl\n",
    "\n",
    "### **Assignment 3**\n",
    "This assignment is concerned with performing an analysis of and execute PageRank on the wikipedia links given in the `wikilink_graph.2004-03-01.csv` file. In order to do this the assignment is split up into four subtasks with each subtask receiving its dedicated `.ipynb` file. See each specific file for details on what this notebook accomplishes.\n",
    "\n",
    "Note all implementations are based on the assignment guidelines and helper files given as well as the documentation of the used functions. \n",
    "\n",
    "#### **PageRank Algorithm (Improved)**\n",
    "This notebook executes the PageRank algorithm using the improved storage method and algorithm as presented in the lecture (see also slide 18 of the instructional slideset). Additionally, some basic analaysis is performed and the results are compared to the \"Sparse\" implementation of PageRank.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Functions**\n",
    "This section contains functions which aid and simplify the code.\n",
    "___\n",
    "The following snippet handles all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `PageRank` is our implementation for the Pagerank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageRank():\n",
    "    def __init__(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_prepped_data` function is responsible for retrieving the data prepped by `prep.ipynb` and loading it for exploratory data analysis.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `filename` - the name of the file containing the prepped data [default = `prep-data.npz`]\n",
    "  \n",
    "Additionally, it returns the following value:\n",
    "  * `data` - an array representing the prepped data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepped_data(filename = 'prep_data.npz'):\n",
    "    data = scipy.sparse.load_npz(filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet triggers data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_prepped_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `convert_to_custom_format` function is responsible for converting the transition matrix from a sparse matrix representation to the custom format specified in slide 17 of the instructional slideset. It is assumed that the in the sparse matrix each (nonempty) column represents a source node.\n",
    "\n",
    "In order to do this the function uses the following parameters:\n",
    "  * `data` - the data as a sparse matrix\n",
    "  \n",
    "Additionally, it returns the following value:\n",
    "  * `converted` - an array representing the converted data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_custom_format(data):\n",
    "    indices = data.nonzero()\n",
    "    dictionary = defaultdict(list)\n",
    "    np_degree = []\n",
    "\n",
    "    for source, destination in zip(indices[1], indices[0]):\n",
    "        dictionary[source].append(destination)\n",
    "    \n",
    "    for s,d in dictionary.items():\n",
    "        np_degree += [[s,len(d),np.array(d)]]\n",
    "    \n",
    "    return(np.array(np_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.5 µs ± 4.58 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# TODO TEMPORARY\n",
    "%timeit convert_to_custom_format(simple_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%time convert_to_custom_format(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = convert_to_custom_format(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVE EVERTHING BELOW THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1]\n",
      " [0 0 1 1]\n",
      " [1 0 0 0]\n",
      " [1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# TODO REMOVE ME I AM TEMPORARY!\n",
    "simple_data = load_prepped_data('simple_data.npz')\n",
    "print(simple_data.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data.shape[0]\n",
    "v_old = np.repeat(1.0 / N , N)\n",
    "Beta = 0.8\n",
    "v_new = np.repeat((1-Beta) / N, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun\n",
    "\n",
    "\n",
    "v_new = np.repeat((1-Beta) / N, N)\n",
    "for i in range(len(M)):\n",
    "    degree = M[i,[1]]\n",
    "    destinations = M[i,[2]]\n",
    "#     print(f'Degree is {degree}, destinations are {destinations}')\n",
    "    for destination in destinations[0]:\n",
    "#         print(f'v_new for {destination} is {v_new[destination]}')\n",
    "        v_new[destination] += Beta * v_old[destination] / degree\n",
    "#         print(f'v_new for {destination} is {v_new[destination]}')\n",
    "    \n",
    "# analyse iteration\n",
    "# MSE: v_old vs. v_new\n",
    "# v_old == v_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
